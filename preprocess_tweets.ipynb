{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "797     Found something historic?\\nDon’t want to forge...\n",
       "7431    Our children's health and prosperity is too im...\n",
       "5674    You become like the 5 people you spend most of...\n",
       "5246    Tune in LIVE to our NASA Innovative Advanced C...\n",
       "8823                           pic.twitter.com/WQThgHWcg4\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./scraped_tweets.csv').sample(frac=1)\n",
    "\n",
    "print(len(df.index))\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797     Found something historic? Don’t want to forget...\n",
       "7431    Our children's health and prosperity is too im...\n",
       "5674    You become like the people you spend most of y...\n",
       "5246    Tune in LIVE to our NASA Innovative Advanced C...\n",
       "8823                                                     \n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess tweets - remove @, # and links.\n",
    "\n",
    "import preprocessor as p\n",
    "\n",
    "df['clean_text'] = df['text'].apply(lambda text: p.clean(str(text)))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797     found something historic? don’t want to forget...\n",
       "7431    our children's health and prosperity is too im...\n",
       "5674    you become like the people you spend most of y...\n",
       "5246    tune in live to our nasa innovative advanced c...\n",
       "8823                                                     \n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to lowercase.\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: text.lower())\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797     found something historic dont want to forget a...\n",
       "7431    our childrens health and prosperity is too imp...\n",
       "5674    you become like the people you spend most of y...\n",
       "5246    tune in live to our nasa innovative advanced c...\n",
       "8823                                                     \n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation.\n",
    "\n",
    "df['clean_text'] = df['clean_text'].str.replace('[^\\w\\s]', '')\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797     found something historic dont want to forget a...\n",
       "7431    our childrens health and prosperity is too imp...\n",
       "5674    you become like the people you spend most of y...\n",
       "5246    tune in live to our nasa innovative advanced c...\n",
       "8823                                                     \n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove whitespaces.\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: str(text).strip())\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "797     found something historic dont want to forget a...\n",
       "7431    our childrens health and prosperity is too imp...\n",
       "5674    you become like the people you spend most of y...\n",
       "5246    tune in live to our nasa innovative advanced c...\n",
       "8138            unaltra importante vittoria forza ragazzi\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove empty texts.\n",
    "\n",
    "df = df.drop(df[df['clean_text'] == ''].index)\n",
    "\n",
    "print(len(df.index))\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "797     found something historic dont want to forget a...\n",
       "7431    our childrens health and prosperity is too imp...\n",
       "5674    you become like the people you spend most of y...\n",
       "5246    tune in live to our nasa innovative advanced c...\n",
       "2184         coach genesio to leave lyon at end of season\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include only English texts.\n",
    "from langdetect import detect\n",
    "\n",
    "# print(\"Detecting languages: 0.00%...\", end=\"\\r\")\n",
    "# for idx, text in enumerate(df['clean_text'].values):\n",
    "#     print(\"Detecting languages: {:.2f}%...\".format((idx + 1) / len(df.index) * 100), end=\"\\r\")\n",
    "#     try:\n",
    "#         detect(text)\n",
    "#     except Exception:\n",
    "#         print('text: (', text, ')')\n",
    "\n",
    "df['lang'] = df['clean_text'].apply(lambda text: detect(text))\n",
    "df = df.drop(df[df['lang'] != 'en'].index)\n",
    "\n",
    "print(len(df.index))\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797     found something historic dont want to forget a...\n",
       "7431    our childrens health and prosperity is too imp...\n",
       "5674    you become like the people you spend most of y...\n",
       "5246    tune in live to our nasa innovative advanced c...\n",
       "2184         coach genesio to leave lyon at end of season\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatize texts.\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: ' '.join(lemmatizer.lemmatize(word) for word in text.split()))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797     found something historic dont want to forget a...\n",
       "7431    our health and prosperity is too important to ...\n",
       "5674    you become like the people you spend most of y...\n",
       "5246    tune in live to our innovative advanced concep...\n",
       "2184                      coach to leave at end of season\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove non-English words.\n",
    "\n",
    "from nltk.corpus import words\n",
    "words = set(words.words())\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: ' '.join(word for word in text.split() if word in words))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797     found something historic dont want forget joke...\n",
       "7431    health prosperity important ignore consequence...\n",
       "5674                        become like people spend time\n",
       "5246    tune live innovative advanced concept symposiu...\n",
       "2184                               coach leave end season\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: ' '.join(word for word in text.split() if word not in stopwords))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new       789\n",
       "u         619\n",
       "ha        553\n",
       "today     499\n",
       "people    495\n",
       "one       490\n",
       "say       462\n",
       "wa        407\n",
       "year      396\n",
       "live      380\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove common words.\n",
    "\n",
    "freq = pd.Series(' '.join(df['clean_text']).split()).value_counts()[:10]\n",
    "\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797     found something historic dont want forget joke...\n",
       "7431    health prosperity important ignore consequence...\n",
       "5674                               become like spend time\n",
       "5246    tune innovative advanced concept symposium hea...\n",
       "2184                               coach leave end season\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: ' '.join(word for word in text.split() if word not in freq))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fled           4\n",
       "cyclone        4\n",
       "neighbor       4\n",
       "warrant        4\n",
       "forecast       4\n",
       "holocaust      4\n",
       "surrounding    4\n",
       "comfort        4\n",
       "visibility     4\n",
       "repeat         4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rare words.\n",
    "\n",
    "freq = pd.Series(' '.join(df['clean_text']).split()).value_counts()[pd.Series(' '.join(df['clean_text']).split()).value_counts() < 5]\n",
    "\n",
    "freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797     found something historic dont want forget joke...\n",
       "7431    health prosperity important ignore consequence...\n",
       "5674                               become like spend time\n",
       "5246    tune innovative advanced concept symposium hea...\n",
       "2184                               coach leave end season\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: ' '.join(word for word in text.split() if word not in freq))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize texts (Not needed).\n",
    "\n",
    "# from nltk import word_tokenize\n",
    "\n",
    "# tokenized_texts = []\n",
    "# for text in df['clean_text'].values:\n",
    "#     tokenized_texts.append(word_tokenize(text))\n",
    "\n",
    "# tokenized_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>want</td>\n",
       "      <td>3</td>\n",
       "      <td>3.967999</td>\n",
       "      <td>11.903997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whenever</td>\n",
       "      <td>1</td>\n",
       "      <td>6.723395</td>\n",
       "      <td>6.723395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>article</td>\n",
       "      <td>1</td>\n",
       "      <td>5.510373</td>\n",
       "      <td>5.510373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>save</td>\n",
       "      <td>1</td>\n",
       "      <td>5.655555</td>\n",
       "      <td>5.655555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>something</td>\n",
       "      <td>1</td>\n",
       "      <td>4.643954</td>\n",
       "      <td>4.643954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       words  tf       idf     tf-idf\n",
       "0       want   3  3.967999  11.903997\n",
       "1   whenever   1  6.723395   6.723395\n",
       "2    article   1  5.510373   5.510373\n",
       "3       save   1  5.655555   5.655555\n",
       "4  something   1  4.643954   4.643954"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create TF-IDF (1 text).\n",
    "import numpy as np\n",
    "\n",
    "tfidf = df['clean_text'][0:1].apply(lambda text: pd.value_counts(text.split(\" \"))).sum(axis=0).reset_index()\n",
    "tfidf.columns = ['words', 'tf']\n",
    "for i, word in enumerate(tfidf['words']):\n",
    "    tfidf.loc[i, 'idf'] = np.log(df.shape[0] / len(df[df['clean_text'].str.contains(word)]))\n",
    "tfidf['tf-idf'] = tfidf['tf'] * tfidf['idf']\n",
    "\n",
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>absence</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abuse</th>\n",
       "      <th>academic</th>\n",
       "      <th>accept</th>\n",
       "      <th>...</th>\n",
       "      <th>ya</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youve</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2650 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abide  ability  able  aboard  absence  absolute  absolutely  abuse  \\\n",
       "0    0.0      0.0   0.0     0.0      0.0       0.0         0.0    0.0   \n",
       "1    0.0      0.0   0.0     0.0      0.0       0.0         0.0    0.0   \n",
       "2    0.0      0.0   0.0     0.0      0.0       0.0         0.0    0.0   \n",
       "3    0.0      0.0   0.0     0.0      0.0       0.0         0.0    0.0   \n",
       "4    0.0      0.0   0.0     0.0      0.0       0.0         0.0    0.0   \n",
       "\n",
       "   academic  accept  ...   ya  yellow  yes  yesterday  yet  york  young  \\\n",
       "0       0.0     0.0  ...  0.0     0.0  0.0        0.0  0.0   0.0    0.0   \n",
       "1       0.0     0.0  ...  0.0     0.0  0.0        0.0  0.0   0.0    0.0   \n",
       "2       0.0     0.0  ...  0.0     0.0  0.0        0.0  0.0   0.0    0.0   \n",
       "3       0.0     0.0  ...  0.0     0.0  0.0        0.0  0.0   0.0    0.0   \n",
       "4       0.0     0.0  ...  0.0     0.0  0.0        0.0  0.0   0.0    0.0   \n",
       "\n",
       "   youve  zero  zone  \n",
       "0    0.0   0.0   0.0  \n",
       "1    0.0   0.0   0.0  \n",
       "2    0.0   0.0   0.0  \n",
       "3    0.0   0.0   0.0  \n",
       "4    0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 2650 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create TF-IDF (all texts).\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = pd.DataFrame(vectorizer.fit_transform(df['clean_text']).toarray())\n",
    "tfidf.columns = vectorizer.get_feature_names()\n",
    "\n",
    "tfidf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
