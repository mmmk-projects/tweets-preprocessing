{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7335    Judge Garland is highly qualified for the benc...\n",
       "4726    Agree - so important to attract girls to tech ...\n",
       "6163    Dispelling both the pleasant and the unpleasan...\n",
       "7378    Rising sea levels are already flooding homes a...\n",
       "957     Five days of Deepavali celebrations begin toda...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./scraped_tweets.csv').sample(frac=1)\n",
    "\n",
    "print(len(df.index))\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7335    Judge Garland is highly qualified for the benc...\n",
       "4726    Agree - so important to attract girls to tech ...\n",
       "6163    Dispelling both the pleasant and the unpleasan...\n",
       "7378    Rising sea levels are already flooding homes a...\n",
       "957     Five days of Deepavali celebrations begin toda...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess tweets - remove @, # and links.\n",
    "\n",
    "import preprocessor as p\n",
    "\n",
    "df['clean_text'] = df['text'].apply(lambda text: p.clean(str(text)))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7335    judge garland is highly qualified for the benc...\n",
       "4726    agree - so important to attract girls to tech ...\n",
       "6163    dispelling both the pleasant and the unpleasan...\n",
       "7378    rising sea levels are already flooding homes a...\n",
       "957     five days of deepavali celebrations begin toda...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to lowercase.\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: text.lower())\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7335    judge garland is highly qualified for the benc...\n",
       "4726    agree  so important to attract girls to tech c...\n",
       "6163    dispelling both the pleasant and the unpleasan...\n",
       "7378    rising sea levels are already flooding homes a...\n",
       "957     five days of deepavali celebrations begin toda...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation.\n",
    "\n",
    "df['clean_text'] = df['clean_text'].str.replace('[^\\w\\s]', '')\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7335    judge garland is highly qualified for the benc...\n",
       "4726    agree  so important to attract girls to tech c...\n",
       "6163    dispelling both the pleasant and the unpleasan...\n",
       "7378    rising sea levels are already flooding homes a...\n",
       "957     five days of deepavali celebrations begin toda...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove whitespaces.\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: str(text).strip())\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7335    judge garland is highly qualified for the benc...\n",
       "4726    agree  so important to attract girls to tech c...\n",
       "6163    dispelling both the pleasant and the unpleasan...\n",
       "7378    rising sea levels are already flooding homes a...\n",
       "957     five days of deepavali celebrations begin toda...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove empty texts.\n",
    "\n",
    "df = df.drop(df[df['clean_text'] == ''].index)\n",
    "\n",
    "print(len(df.index))\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Include only English texts.\n",
    "from langdetect import detect\n",
    "\n",
    "# print(\"Detecting languages: 0.00%...\", end=\"\\r\")\n",
    "# for idx, text in enumerate(df['clean_text'].values):\n",
    "#     print(\"Detecting languages: {:.2f}%...\".format((idx + 1) / len(df.index) * 100), end=\"\\r\")\n",
    "#     try:\n",
    "#         detect(text)\n",
    "#     except Exception:\n",
    "#         print('text: (', text, ')')\n",
    "\n",
    "df['lang'] = df['clean_text'].apply(lambda text: detect(text))\n",
    "df = df.drop(df[df['lang'] != 'en'].index)\n",
    "\n",
    "print(len(df.index))\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize texts.\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: ' '.join(lemmatizer.lemmatize(word) for word in text.split()))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-English words.\n",
    "\n",
    "from nltk.corpus import words\n",
    "words = set(words.words())\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: ' '.join(word for word in text.split() if word in words))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: ' '.join(word for word in text.split() if word not in stopwords))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove common words.\n",
    "\n",
    "freq = pd.Series(' '.join(df['clean_text']).split()).value_counts()[pd.Series(' '.join(df['clean_text']).split()).value_counts() > 300]\n",
    "\n",
    "freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = list(freq.index)\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: ' '.join(word for word in text.split() if word not in freq))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rare words.\n",
    "\n",
    "freq = pd.Series(' '.join(df['clean_text']).split()).value_counts()[pd.Series(' '.join(df['clean_text']).split()).value_counts() < 3]\n",
    "\n",
    "freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = list(freq.index)\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: ' '.join(word for word in text.split() if word not in freq))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize texts (Not needed).\n",
    "\n",
    "# from nltk import word_tokenize\n",
    "\n",
    "# tokenized_texts = []\n",
    "# for text in df['clean_text'].values:\n",
    "#     tokenized_texts.append(word_tokenize(text))\n",
    "\n",
    "# tokenized_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF (1 text).\n",
    "import numpy as np\n",
    "\n",
    "tfidf = df['clean_text'][0:1].apply(lambda text: pd.value_counts(text.split(\" \"))).sum(axis=0).reset_index()\n",
    "tfidf.columns = ['words', 'tf']\n",
    "for i, word in enumerate(tfidf['words']):\n",
    "    tfidf.loc[i, 'idf'] = np.log(df.shape[0] / len(df[df['clean_text'].str.contains(word)]))\n",
    "tfidf['tf-idf'] = tfidf['tf'] * tfidf['idf']\n",
    "\n",
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF (all texts).\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "matrix = vectorizer.fit_transform(df['clean_text'])\n",
    "tfidf = pd.DataFrame(matrix.toarray())\n",
    "tfidf.columns = vectorizer.get_feature_names()\n",
    "\n",
    "tfidf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
