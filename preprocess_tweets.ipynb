{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    What a weekend so far. Have you been watching ...\n",
       "1     See who's stopping by the #YouTubeMusic loung...\n",
       "2    Yes, we're still running the numbers, but we c...\n",
       "3    We're just getting started. Keep tuning into t...\n",
       "4    Cannot WAIT to see what Donald has up his slee...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read from CSV file.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./scraped_tweets.csv').dropna(subset=['text'])\n",
    "\n",
    "print(len(df.index))\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    What a weekend so far. Have you been watching ...\n",
       "1    See who's stopping by the lounge at ! And tune...\n",
       "2    Yes, we're still running the numbers, but we c...\n",
       "3    We're just getting started. Keep tuning into t...\n",
       "4    Cannot WAIT to see what Donald has up his slee...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess tweets - remove @, # and links.\n",
    "\n",
    "import preprocessor as p\n",
    "\n",
    "df['clean_text'] = df['text'].apply(lambda text: p.clean(str(text)))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    what a weekend so far. have you been watching ...\n",
       "1    see who's stopping by the lounge at ! and tune...\n",
       "2    yes, we're still running the numbers, but we c...\n",
       "3    we're just getting started. keep tuning into t...\n",
       "4    cannot wait to see what donald has up his slee...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to lowercase.\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: text.lower())\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    what a weekend so far. have you been watching ...\n",
       "1    see who is stopping by the lounge at ! and tun...\n",
       "2    yes, we are still running the numbers, but we ...\n",
       "3    we are just getting started. keep tuning into ...\n",
       "4    cannot wait to see what donald has up his slee...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove contractions.\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_contractions(text):\n",
    "    text = re.sub(r'â€™', '\\'', text)\n",
    "    \n",
    "    text = re.sub(r'won\\'t', 'will not', text)\n",
    "    text = re.sub(r'can\\'t', 'can not', text)\n",
    "    \n",
    "    text = re.sub(r'\\'s', ' is', text)\n",
    "    text = re.sub(r'\\'m', ' am', text)\n",
    "    text = re.sub(r'\\'re', ' are', text)\n",
    "    text = re.sub(r'\\'ve', ' have', text)\n",
    "    text = re.sub(r'\\'ll', ' will', text)\n",
    "    text = re.sub(r'\\'d', ' would', text)\n",
    "    text = re.sub(r'\\'t', ' not', text)\n",
    "    text = re.sub(r'n\\'t', ' not', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(remove_contractions)\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    what a weekend so far have you been watching t...\n",
       "1    see who is stopping by the lounge at  and tune...\n",
       "2    yes we are still running the numbers but we ca...\n",
       "3    we are just getting started keep tuning into t...\n",
       "4    cannot wait to see what donald has up his slee...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuations.\n",
    "\n",
    "df['clean_text'] = df['clean_text'].str.replace('[^\\w\\s]', '')\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    what a weekend so far have you been watching t...\n",
       "1    see who is stopping by the lounge at  and tune...\n",
       "2    yes we are still running the numbers but we ca...\n",
       "3    we are just getting started keep tuning into t...\n",
       "4    cannot wait to see what donald has up his slee...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove whitespaces.\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: str(text).strip())\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    what a weekend so far have you been watching t...\n",
       "1    see who is stopping by the lounge at  and tune...\n",
       "2    yes we are still running the numbers but we ca...\n",
       "3    we are just getting started keep tuning into t...\n",
       "4    cannot wait to see what donald has up his slee...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove empty texts.\n",
    "\n",
    "df = df.drop(df[df['clean_text'] == ''].index)\n",
    "\n",
    "print(len(df.index))\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    what a weekend so far have you been watching t...\n",
       "1    see who is stopping by the lounge at  and tune...\n",
       "2    yes we are still running the numbers but we ca...\n",
       "3    we are just getting started keep tuning into t...\n",
       "4    cannot wait to see what donald has up his slee...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include only English texts.\n",
    "from langdetect import detect\n",
    "\n",
    "# print(\"Detecting languages: 0.00%...\", end=\"\\r\")\n",
    "# for idx, text in enumerate(df['clean_text'].values):\n",
    "#     print(\"Detecting languages: {:.2f}%...\".format((idx + 1) / len(df.index) * 100), end=\"\\r\")\n",
    "#     try:\n",
    "#         detect(text)\n",
    "#     except Exception:\n",
    "#         print('text: (', text, ')')\n",
    "\n",
    "df['lang'] = df['clean_text'].apply(lambda text: detect(text))\n",
    "df = df.drop(df[df['lang'] != 'en'].index)\n",
    "\n",
    "print(len(df.index))\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    what a weekend so far have you been watching t...\n",
       "1    see who is stopping by the lounge at and tune ...\n",
       "2    yes we are still running the number but we can...\n",
       "3    we are just getting started keep tuning into t...\n",
       "4    cannot wait to see what donald ha up his sleev...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatize texts.\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: ' '.join(lemmatizer.lemmatize(word) for word in text.split()))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     what a weekend so far have you been watching the\n",
       "1    see who is stopping by the lounge at and tune ...\n",
       "2    yes we are still running the number but we can...\n",
       "3    we are just getting keep tuning into the all w...\n",
       "4    cannot wait to see what ha up his sleeve tune ...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove non-English words.\n",
    "\n",
    "from nltk.corpus import words\n",
    "words = set(words.words())\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: ' '.join(word for word in text.split() if word in words))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 weekend far watching\n",
       "1         see stopping lounge tune live stream weekend\n",
       "2    yes still running number confirm officially ho...\n",
       "3                     getting keep tuning weekend long\n",
       "4              cannot wait see ha sleeve tune live min\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: ' '.join(word for word in text.split() if word not in stopwords))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new       756\n",
       "u         620\n",
       "ha        559\n",
       "one       486\n",
       "people    483\n",
       "today     481\n",
       "say       468\n",
       "year      406\n",
       "wa        399\n",
       "live      377\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove common words.\n",
    "\n",
    "freq = pd.Series(' '.join(df['clean_text']).split()).value_counts()[pd.Series(' '.join(df['clean_text']).split()).value_counts() > 300]\n",
    "\n",
    "freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 weekend far watching\n",
       "1                  stopping lounge tune stream weekend\n",
       "2    yes still running number confirm officially ho...\n",
       "3                     getting keep tuning weekend long\n",
       "4                          cannot wait sleeve tune min\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: ' '.join(word for word in text.split() if word not in freq))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "waffle       3\n",
       "virtually    3\n",
       "tractor      3\n",
       "monitor      3\n",
       "warming      3\n",
       "ought        3\n",
       "renewable    3\n",
       "largely      3\n",
       "midrange     3\n",
       "luxury       3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rare words.\n",
    "\n",
    "freq = pd.Series(' '.join(df['clean_text']).split()).value_counts()[pd.Series(' '.join(df['clean_text']).split()).value_counts() <= 3]\n",
    "\n",
    "freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 weekend far watching\n",
       "1                         stopping tune stream weekend\n",
       "2    yes still running number confirm officially ho...\n",
       "3                            getting keep weekend long\n",
       "4                                     cannot wait tune\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda text: ' '.join(word for word in text.split() if word not in freq))\n",
    "\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                 weekend far watching\n",
       "1                         stopping tune stream weekend\n",
       "2    yes still running number confirm officially ho...\n",
       "3                            getting keep weekend long\n",
       "4                                     cannot wait tune\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove more empty texts.\n",
    "\n",
    "df = df.drop(df[df['clean_text'] == ''].index)\n",
    "\n",
    "print(len(df.index))\n",
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9105"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write cleaned texts to CSV file.\n",
    "\n",
    "df = df.dropna(subset=['clean_text'])\n",
    "df.to_csv('./clean_text.csv', columns=['clean_text'], index=False)\n",
    "\n",
    "len(df.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
